{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8dea6b",
   "metadata": {},
   "source": [
    "# SKELETON DANCE USING OPENCV & MIDEAPIPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542b619",
   "metadata": {},
   "source": [
    "### MEDIAPIPE POSE :\n",
    "    Human pose estimation from video plays a critical role in various applications such as quantifying physical exercises,\n",
    "    sign language recognition, and full-body gesture control. For example, it can form the basis for yoga, dance, and fitnes  \n",
    "    applications.It can also enable the overlay of digital content and information on top of the physical world in augmented       reality.\n",
    "    \n",
    "#### REFRENCE : https://google.github.io/mediapipe/solutions/pose.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96359eda",
   "metadata": {},
   "source": [
    "# import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab2b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51346d83",
   "metadata": {},
   "source": [
    "# open cv : \n",
    "####  generally is used for computer visison .OpenCV-Python is a library of Python bindings designed to solve computer vision problems.OpenCV-Python makes use of Numpy, which is a highly optimized library for numerical operations with a MATLAB-style syntax. All the OpenCV array structures are converted to and from Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c87fc",
   "metadata": {},
   "source": [
    "# mediapipe for pose :\n",
    "#### MediaPipe Pose is a ML solution for high-fidelity body pose tracking, inferring 33 3D landmarks and background segmentation mask on the whole body from RGB video frames utilizing our BlazePose research that also powers the ML Kit Pose Detection API. Current state-of-the-art approaches rely primarily on powerful desktop environments for inference, whereas our method achieves real-time performance on most modern mobile phones, desktops/laptops, in python and even on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa027bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_image = cv2.VideoCapture(0)\n",
    "# We need to create a VideoCapture object to capture a video. It accepts either the device index or the name of a video file\n",
    "capture_image.set(10,150)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28dbf270",
   "metadata": {},
   "outputs": [],
   "source": [
    "pTime = 0\n",
    "mpPose = mp.solutions.pose\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mp_drawing = mp.solutions.drawing_styles\n",
    "pose = mpPose.Pose(\n",
    "     min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34824cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while capture_image.isOpened():\n",
    "    ret, frame = capture_image.read()\n",
    "    if not ret:\n",
    "        break\n",
    "# is Opened() In a real-time video monitoring system,\n",
    "# to ensure that the camera is opened and working properly we have isOpened() of OpenCV.        \n",
    "    frame= cv2.resize(frame, (900, 568))\n",
    "    \n",
    "# After open camera, we can display the video frame by frame.\n",
    "    \n",
    "    frame.flags.writeable = False\n",
    "    BG_COLOR = (150, 195, 192)\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "\n",
    "\n",
    "    frame.flags.writeable = True\n",
    "    main = results.pose_landmarks\n",
    "    if results.pose_landmarks :\n",
    "    \n",
    "# pose landmark is a real-time feed plays a crucial role in various fields such as full-body gesture control,\n",
    "# bquantifying physical exercise, and sign language recognition\n",
    "        \n",
    "        for landmark in main.landmark:\n",
    "            landmark.x+= 0.4\n",
    "            \n",
    " \n",
    "        mpDraw.draw_landmarks(frame, results.pose_landmarks, mpPose.POSE_CONNECTIONS,  connection_drawing_spec= mpDraw.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "      \n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "# after that we use cv2. imshow() method is used to display an image in a window. \n",
    "\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Python Opencv destroyAllWindow() function allows users to destroy all windows at any time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df9bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
